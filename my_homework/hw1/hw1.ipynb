{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ROLLOUT_PATH='/home/puzi/RL/my_homework/hw1/rollouts'\n",
    "MAX_ITER=100000\n",
    "MAX_EPOCHS=100\n",
    "NUM_EPOCHS_VAL=1\n",
    "BATCH_SIZE=512\n",
    "HIDDEN_UNITS1=128\n",
    "HIDDEN_UNITS2=128\n",
    "BASE_LR=0.01\n",
    "NUM_LR_REDUCTIONS=3\n",
    "RENDER=True\n",
    "L2_REG_FACTOR=0.05\n",
    "VERBOSE=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ant-v1', 'Reacher-v1', 'Hopper-v1', 'Humanoid-v1', 'HalfCheetah-v1', 'Walker2d-v1']\n"
     ]
    }
   ],
   "source": [
    "envs=glob.glob(os.path.join(ROLLOUT_PATH,'*pkl'))\n",
    "envs=[os.path.basename(s)[:-12] for s in envs]\n",
    "print (envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ENV_NAME=envs[-1]\n",
    "fi=open(os.path.join(ROLLOUT_PATH,ENV_NAME+'_rollout.pkl'),'r')\n",
    "data=pickle.load(fi)\n",
    "fi.close()\n",
    "\n",
    "obs=data['observations']\n",
    "act=data['actions']\n",
    "rewards=data['returns']\n",
    "\n",
    "#random.shuffle(obs)\n",
    "#random.shuffle(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 17)\n",
      "(50000, 6)\n"
     ]
    }
   ],
   "source": [
    "act=act.reshape((act.shape[0],act.shape[-1]))\n",
    "print (obs.shape)\n",
    "print (act.shape)\n",
    "\n",
    "\n",
    "input_size=obs.shape[-1]\n",
    "output_size=act.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(obs, act, test_size=0.15)#, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 17)\n",
      "(42500, 6)\n",
      "(7500, 17)\n",
      "(7500, 6)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_val.shape\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ITER_PER_EPOCH=x_train.shape[0]/BATCH_SIZE+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean=np.mean(x_train, axis=0)\n",
    "stdev=np.std(x_train, axis=0)\n",
    "\n",
    "x_train-=mean\n",
    "x_train/=stdev\n",
    "\n",
    "x_val-=mean\n",
    "x_val/=stdev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "x = tf.placeholder(tf.float32, [None, input_size])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, output_size])\n",
    "\n",
    "\n",
    "HIDDEN_UNITS1=128\n",
    "\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights = tf.Variable(tf.truncated_normal([input_size, HIDDEN_UNITS1],stddev=1.0 / math.sqrt(float(input_size))),name='weights')\n",
    "    #weights = tf.Variable(tf.truncated_normal([input_size, HIDDEN_UNITS1],stddev=1.0),name='weights')\n",
    "    biases = tf.Variable(tf.zeros([HIDDEN_UNITS1])+0.1,name='biases')\n",
    "    hidden1_reg=tf.nn.l2_loss(weights)+tf.nn.l2_loss(biases)\n",
    "\n",
    "    hidden1 = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "\n",
    "\n",
    "with tf.name_scope('regress'):\n",
    "    weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS1, output_size],stddev=1.0 / math.sqrt(float(output_size))),name='weights')\n",
    "    #weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS2, output_size],stddev=1.0),name='weights')\n",
    "    biases = tf.Variable(tf.zeros([output_size])+0.1,name='biases')\n",
    "    regress_reg=tf.nn.l2_loss(weights)+tf.nn.l2_loss(biases)\n",
    "\n",
    "    output = tf.nn.tanh(tf.matmul(hidden1, weights) + biases)\n",
    "    pred_loss=tf.losses.mean_squared_error(y_,output)\n",
    "\n",
    "loss=pred_loss+L2_REG_FACTOR*(hidden1_reg+regress_reg)\n",
    "\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "#lr=tf.Variable(BASE_LR,name='lr',trainable=False)\n",
    "lr=tf.train.exponential_decay(BASE_LR,global_step, ITER_PER_EPOCH*(MAX_EPOCHS/NUM_LR_REDUCTIONS),0.01,staircase=True)\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "#optimizer=tf.train.MomentumOptimizer(learning_rate=lr,momentum=0.005,use_nesterov=True)\n",
    "\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "epoch_loss=[]\n",
    "epoch1_loss=[]\n",
    "val_dist=[]\n",
    "print \"Training Net\"\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    start=time.time()\n",
    "    if epoch>MAX_EPOCHS/NUM_LR_REDUCTIONS*2+10:\n",
    "        if float(val_dist[-10]-val_dist[-1])/val_dist[-1]<0.01:\n",
    "            print \"No improvemet in Val accuracy over last 10 epochs, terminating\"\n",
    "            break\n",
    "    #if epoch>0 and epoch%(MAX_EPOCHS/NUM_LR_REDUCTIONS)==0:\n",
    "        #lr=lr/float(100)\n",
    "    for iter in range(ITER_PER_EPOCH):\n",
    "        batch_x=x_train[:BATCH_SIZE,:]\n",
    "        batch_y=y_train[:BATCH_SIZE,:]\n",
    "        x_train=np.append(x_train[BATCH_SIZE:,:],x_train[:BATCH_SIZE,:],axis=0)\n",
    "        y_train=np.append(y_train[BATCH_SIZE:,:],y_train[:BATCH_SIZE,:],axis=0)\n",
    "        _,p_loss, loss_value = sess.run([train_op, pred_loss,loss],feed_dict={x:batch_x,y_:batch_y})\n",
    "        if epoch==0:\n",
    "            epoch1_loss.append(loss_value)\n",
    "            if VERBOSE:\n",
    "                print \"Epoch=0, Iteration=\",str(iter), \" loss=\",str(loss_value)\n",
    "    epoch_loss.append(loss_value)\n",
    "    print \"Finished running epoch=\",str(epoch), \"loss=\",str(loss_value),\"epoc duration=\",str(time.time()-start), \"seconds\"\n",
    "    if epoch%NUM_EPOCHS_VAL==0:\n",
    "        print \"Evaluating validation set\"\n",
    "        #pred=sess.run(output,feed_dict={x:x_val})\n",
    "        #pred=output\n",
    "        dist=tf.losses.mean_squared_error(y_val,output)\n",
    "        p,d=sess.run([output, dist],feed_dict={x:x_val})\n",
    "        val_dist.append(d)\n",
    "        print \"Total error=\", str(d)  \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Net\n",
      "Finished running epoch= 0 loss= 5.168 epoc duration= 1.04926395416 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.526072\n",
      "Finished running epoch= 1 loss= 4.69599 epoc duration= 0.946886062622 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.458621\n",
      "Finished running epoch= 2 loss= 4.35603 epoc duration= 0.934782981873 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.432163\n",
      "Finished running epoch= 3 loss= 4.04491 epoc duration= 0.945519924164 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.420124\n",
      "Finished running epoch= 4 loss= 3.75078 epoc duration= 0.972482919693 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.412848\n",
      "Finished running epoch= 5 loss= 3.46871 epoc duration= 0.927798986435 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.408253\n",
      "Finished running epoch= 6 loss= 3.2522 epoc duration= 0.955096960068 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.405837\n",
      "Finished running epoch= 7 loss= 3.01045 epoc duration= 0.934962034225 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.405372\n",
      "Finished running epoch= 8 loss= 2.80604 epoc duration= 0.939691066742 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.406356\n",
      "Finished running epoch= 9 loss= 2.66544 epoc duration= 0.946387052536 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.408325\n",
      "Finished running epoch= 10 loss= 2.5317 epoc duration= 0.967642068863 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.410955\n",
      "Finished running epoch= 11 loss= 2.36483 epoc duration= 0.962249040604 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.414074\n",
      "Finished running epoch= 12 loss= 2.19525 epoc duration= 0.935827970505 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.417569\n",
      "Finished running epoch= 13 loss= 2.10257 epoc duration= 0.928526163101 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.421265\n",
      "Finished running epoch= 14 loss= 1.99029 epoc duration= 0.943315029144 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.42506\n",
      "Finished running epoch= 15 loss= 1.89006 epoc duration= 0.922989845276 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.428933\n",
      "Finished running epoch= 16 loss= 1.8247 epoc duration= 1.19386386871 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.432817\n",
      "Finished running epoch= 17 loss= 1.71738 epoc duration= 0.997574090958 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.436697\n",
      "Finished running epoch= 18 loss= 1.62752 epoc duration= 0.938944101334 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.440493\n",
      "Finished running epoch= 19 loss= 1.55514 epoc duration= 0.933924913406 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.44422\n",
      "Finished running epoch= 20 loss= 1.49987 epoc duration= 0.932682991028 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.447863\n",
      "Finished running epoch= 21 loss= 1.43088 epoc duration= 0.937036037445 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.451459\n",
      "Finished running epoch= 22 loss= 1.39816 epoc duration= 0.950124025345 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.454935\n",
      "Finished running epoch= 23 loss= 1.34843 epoc duration= 0.937440872192 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.458316\n",
      "Finished running epoch= 24 loss= 1.31909 epoc duration= 0.942394018173 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.461557\n",
      "Finished running epoch= 25 loss= 1.24175 epoc duration= 0.924894094467 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.464676\n",
      "Finished running epoch= 26 loss= 1.23853 epoc duration= 0.946938037872 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.467623\n",
      "Finished running epoch= 27 loss= 1.19508 epoc duration= 0.936357975006 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.47045\n",
      "Finished running epoch= 28 loss= 1.17272 epoc duration= 0.936089038849 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.473115\n",
      "Finished running epoch= 29 loss= 1.1192 epoc duration= 0.951147079468 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.475667\n",
      "Finished running epoch= 30 loss= 1.1067 epoc duration= 0.945092201233 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.478143\n",
      "Finished running epoch= 31 loss= 1.0558 epoc duration= 0.952496051788 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.48051\n",
      "Finished running epoch= 32 loss= 1.0538 epoc duration= 0.948663949966 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.482772\n",
      "Finished running epoch= 33 loss= 1.01946 epoc duration= 0.943504095078 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.484972\n",
      "Finished running epoch= 34 loss= 1.0049 epoc duration= 0.936602830887 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.487059\n",
      "Finished running epoch= 35 loss= 0.983996 epoc duration= 0.973164081573 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.48908\n",
      "Finished running epoch= 36 loss= 0.973999 epoc duration= 0.936349153519 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.490987\n",
      "Finished running epoch= 37 loss= 0.966654 epoc duration= 0.911797046661 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.492826\n",
      "Finished running epoch= 38 loss= 0.92724 epoc duration= 0.913769006729 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.494591\n",
      "Finished running epoch= 39 loss= 0.924304 epoc duration= 0.973026990891 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.496259\n",
      "Finished running epoch= 40 loss= 0.902403 epoc duration= 0.895156145096 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.497857\n",
      "Finished running epoch= 41 loss= 0.947321 epoc duration= 0.910574197769 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.499348\n",
      "Finished running epoch= 42 loss= 0.900087 epoc duration= 0.910212993622 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.50077\n",
      "Finished running epoch= 43 loss= 0.870722 epoc duration= 0.982993841171 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.502123\n",
      "Finished running epoch= 44 loss= 0.897147 epoc duration= 0.933596849442 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.503391\n",
      "Finished running epoch= 45 loss= 0.878042 epoc duration= 0.910946130753 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.504606\n",
      "Finished running epoch= 46 loss= 0.875556 epoc duration= 0.917392015457 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.505763\n",
      "Finished running epoch= 47 loss= 0.857872 epoc duration= 0.914968013763 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.506859\n",
      "Finished running epoch= 48 loss= 0.884482 epoc duration= 0.986446857452 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.507914\n",
      "Finished running epoch= 49 loss= 0.864801 epoc duration= 0.981384992599 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.508921\n",
      "Finished running epoch= 50 loss= 0.821232 epoc duration= 0.922129869461 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.509888\n",
      "Finished running epoch= 51 loss= 0.846983 epoc duration= 0.933274030685 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.510798\n",
      "Finished running epoch= 52 loss= 0.823845 epoc duration= 0.91203212738 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.511696\n",
      "Finished running epoch= 53 loss= 0.818953 epoc duration= 0.921573877335 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.512562\n",
      "Finished running epoch= 54 loss= 0.843211 epoc duration= 0.952324867249 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.513388\n",
      "Finished running epoch= 55 loss= 0.844912 epoc duration= 0.906017065048 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.514167\n",
      "Finished running epoch= 56 loss= 0.818919 epoc duration= 0.90141415596 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.514899\n",
      "Finished running epoch= 57 loss= 0.795908 epoc duration= 0.926604986191 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.515625\n",
      "Finished running epoch= 58 loss= 0.81647 epoc duration= 0.928196907043 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.516303\n",
      "Finished running epoch= 59 loss= 0.77994 epoc duration= 0.933919906616 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.516968\n",
      "Finished running epoch= 60 loss= 0.814267 epoc duration= 0.938127994537 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.517599\n",
      "Finished running epoch= 61 loss= 0.839685 epoc duration= 0.919486999512 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.518199\n",
      "Finished running epoch= 62 loss= 0.806547 epoc duration= 0.92028093338 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.518766\n",
      "Finished running epoch= 63 loss= 0.818937 epoc duration= 1.02739095688 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.519309\n",
      "Finished running epoch= 64 loss= 0.829395 epoc duration= 0.935762166977 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.519845\n",
      "Finished running epoch= 65 loss= 0.812333 epoc duration= 0.945348978043 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.520341\n",
      "Finished running epoch= 66 loss= 0.783386 epoc duration= 0.953624010086 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.52083\n",
      "Finished running epoch= 67 loss= 0.803976 epoc duration= 0.912791967392 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.521309\n",
      "Finished running epoch= 68 loss= 0.784791 epoc duration= 0.974772930145 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.521778\n",
      "Finished running epoch= 69 loss= 0.774096 epoc duration= 0.93469619751 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.522225\n",
      "Finished running epoch= 70 loss= 0.794746 epoc duration= 0.91739487648 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.522656\n",
      "Finished running epoch= 71 loss= 0.765547 epoc duration= 0.921531915665 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.523081\n",
      "Finished running epoch= 72 loss= 0.799406 epoc duration= 0.937258005142 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.523473\n",
      "Finished running epoch= 73 loss= 0.795326 epoc duration= 0.953034877777 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.523858\n",
      "Finished running epoch= 74 loss= 0.787354 epoc duration= 0.915214061737 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.524229\n",
      "Finished running epoch= 75 loss= 0.767 epoc duration= 1.07256317139 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.524605\n",
      "Finished running epoch= 76 loss= 0.838724 epoc duration= 1.71175289154 seconds\n",
      "Evaluating validation set\n",
      "Total error= 0.524946\n",
      "No improvemet in Val accuracy over last 10 epochs, terminating\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, input_size])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, output_size])\n",
    "\n",
    "\n",
    "HIDDEN_UNITS1=128\n",
    "HIDDEN_UNITS2=64\n",
    "\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights = tf.Variable(tf.truncated_normal([input_size, HIDDEN_UNITS1],stddev=1.0 / math.sqrt(float(input_size))),name='weights')\n",
    "    #weights = tf.Variable(tf.truncated_normal([input_size, HIDDEN_UNITS1],stddev=1.0),name='weights')\n",
    "    biases = tf.Variable(tf.zeros([HIDDEN_UNITS1])+0.1,name='biases')\n",
    "    hidden1_reg=tf.nn.l2_loss(weights)+tf.nn.l2_loss(biases)\n",
    "\n",
    "    hidden1 = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "    tf.summary.histogram('hidden1',hidden1)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS1, HIDDEN_UNITS2],stddev=1.0 / math.sqrt(float(HIDDEN_UNITS1))),name='weights')\n",
    "    #weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS1, HIDDEN_UNITS2],stddev=1.0),name='weights')\n",
    "    biases = tf.Variable(tf.zeros([HIDDEN_UNITS2])+0.1,name='biases')\n",
    "    hidden2_reg=tf.nn.l2_loss(weights)+tf.nn.l2_loss(biases)\n",
    "\n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    tf.summary.histogram('hidden2',hidden2)\n",
    "\n",
    "with tf.name_scope('regress'):\n",
    "    weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS2, output_size],stddev=1.0 / math.sqrt(float(output_size))),name='weights')\n",
    "    #weights = tf.Variable(tf.truncated_normal([HIDDEN_UNITS2, output_size],stddev=1.0),name='weights')\n",
    "    biases = tf.Variable(tf.zeros([output_size])+0.1,name='biases')\n",
    "    regress_reg=tf.nn.l2_loss(weights)+tf.nn.l2_loss(biases)\n",
    "\n",
    "    output = tf.nn.tanh(tf.matmul(hidden2, weights) + biases)\n",
    "    pred_loss=tf.losses.mean_squared_error(y_,output)\n",
    "    tf.summary.histogram('output',output)\n",
    "    tf.summary.scalar('pred_loss',pred_loss)\n",
    "\n",
    "loss=pred_loss+L2_REG_FACTOR*(hidden1_reg+hidden2_reg+regress_reg)\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "#lr=tf.train.exponential_decay(BASE_LR,global_step, ITER_PER_EPOCH*(MAX_EPOCHS/NUM_LR_REDUCTIONS),0.01,staircase=True)\n",
    "lr=tf.constant(0.01)\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "#optimizer=tf.train.MomentumOptimizer(learning_rate=lr,momentum=0.005,use_nesterov=True)\n",
    "\n",
    "\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "tf.summary.scalar('lr',lr)\n",
    "tf.summary.scalar('loss',loss)\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "merged=tf.summary.merge_all()\n",
    "\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "writer=tf.summary.FileWriter('./reports',sess.graph)\n",
    "epoch_loss=[]\n",
    "epoch1_loss=[]\n",
    "val_dist=[]\n",
    "print \"Training Net\"\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    start=time.time()\n",
    "    if epoch>MAX_EPOCHS/NUM_LR_REDUCTIONS*2+10:\n",
    "        if float(val_dist[-10]-val_dist[-1])/val_dist[-1]<0.01:\n",
    "            print \"No improvemet in Val accuracy over last 10 epochs, terminating\"\n",
    "            break\n",
    "    #if epoch>0 and epoch%(MAX_EPOCHS/NUM_LR_REDUCTIONS)==0:\n",
    "        #lr=lr/float(100)\n",
    "    for iter in range(ITER_PER_EPOCH):\n",
    "        batch_x=x_train[:BATCH_SIZE,:]\n",
    "        batch_y=y_train[:BATCH_SIZE,:]\n",
    "        x_train=np.append(x_train[BATCH_SIZE:,:],x_train[:BATCH_SIZE,:],axis=0)\n",
    "        y_train=np.append(y_train[BATCH_SIZE:,:],y_train[:BATCH_SIZE,:],axis=0)\n",
    "        summary,_,p_loss, loss_value = sess.run([merged,train_op, pred_loss,loss],feed_dict={x:batch_x,y_:batch_y})\n",
    "        writer.add_summary(summary,iter)\n",
    "        if epoch==0:\n",
    "            epoch1_loss.append(loss_value)\n",
    "            if VERBOSE:\n",
    "                print \"Epoch=0, Iteration=\",str(iter), \" loss=\",str(loss_value)\n",
    "    epoch_loss.append(loss_value)\n",
    "    print \"Finished running epoch=\",str(epoch), \"loss=\",str(loss_value),\"epoc duration=\",str(time.time()-start), \"seconds\"\n",
    "    if epoch%NUM_EPOCHS_VAL==0:\n",
    "        print \"Evaluating validation set\"\n",
    "        #pred=sess.run(output,feed_dict={x:x_val})\n",
    "        #pred=output\n",
    "        dist=tf.losses.mean_squared_error(y_val,output)\n",
    "        p,d=sess.run([output, dist],feed_dict={x:x_val})\n",
    "        val_dist.append(d)\n",
    "        print \"Total error=\", str(d)  \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAEWCAYAAABhUT6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa948eaee50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss_chart=np.concatenate((epoch1_loss[0],val_dist))\n",
    "train_loss=plt.plot(epoch1_loss[0]+epoch_loss,'b-')\n",
    "plt.setp(train_loss, 'label','training loss')\n",
    "val_loss=plt.plot(epoch1_loss[0]+val_dist,'ro')\n",
    "plt.setp(val_loss, 'label','validation loss')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Training of '+ENV_NAME)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RENDER=False #Comment this line to see env rendering\n",
    "test_rewards=[]\n",
    "env=gym.make(ENV_NAME)\n",
    "max_steps=env.spec.timestep_limit\n",
    "for i in range(len(rewards)):\n",
    "    print \"Running rollout \", str(i)\n",
    "    obs = env.reset()\n",
    "    obs-=mean\n",
    "    obs/=stdev\n",
    "    reward=0\n",
    "    steps=0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action=sess.run(output,feed_dict={x:obs[None,:]})\n",
    "        #print action\n",
    "        obs,r,done,_=env.step(action)\n",
    "        obs-=mean\n",
    "        obs/=stdev\n",
    "        reward+=r\n",
    "        steps+=1\n",
    "        if steps % 100 == 0: \n",
    "            print(\"%i/%i\"%(steps, max_steps))\n",
    "        if RENDER:\n",
    "            env.render()\n",
    "        if steps>max_steps:\n",
    "            break\n",
    "    print str(steps),str(reward)\n",
    "    test_rewards.append(reward)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bbox=plt.boxplot([rewards,test_rewards])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tf_util\n",
    "import load_policy\n",
    "\n",
    "D_INIT_SIZE=40000\n",
    "NUM_DAgger_ITERS=10\n",
    "NUM_OBS_PER_ITER=10000\n",
    "\n",
    "D_x=x_train[:D_INIT_SIZE,:]\n",
    "D_y=y_train[:D_INIT_SIZE,:]\n",
    "\n",
    "policy_fn = load_policy.load_policy(os.path.join('./experts/',ENV_NAME+'.pkl'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "epoch_loss=[]\n",
    "val_dist=[]\n",
    "print \"Training Net\"\n",
    "for i in range(NUM_DAgger_ITERS):\n",
    "    print \"Running DAgger iteration #:\", str(i)\n",
    "    #Train net on D\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        start=time.time()\n",
    "        for iter in range(ITER_PER_EPOCH):\n",
    "            batch_x=D_x[:BATCH_SIZE,:]\n",
    "            batch_y=D_y[:BATCH_SIZE,:]\n",
    "            D_x=np.append(D_x[BATCH_SIZE:,:],D_x[:BATCH_SIZE,:],axis=0)\n",
    "            D_y=np.append(D_y[BATCH_SIZE:,:],D_y[:BATCH_SIZE,:],axis=0)\n",
    "            _, loss_value = sess.run([train_op, loss],feed_dict={x:batch_x,y_:batch_y})\n",
    "        epoch_loss.append(loss_value)\n",
    "        print \"Finished running epoch=\",str(epoch), \"loss=\",str(loss_value),\"epoc duration=\",str(time.time()-start), \"seconds\"\n",
    "        if epoch%NUM_EPOCHS_VAL==0:\n",
    "            print \"Evaluating validation set\"\n",
    "            #pred=sess.run(output,feed_dict={x:x_val})\n",
    "            #pred=output\n",
    "            dist=tf.losses.mean_squared_error(y_val,output)\n",
    "            p,d=sess.run([output, dist],feed_dict={x:x_val})\n",
    "            val_dist.append(d)\n",
    "            print \"Total error=\", str(d)\n",
    "    \n",
    "    #Generate new observations\n",
    "    new_obs=[]\n",
    "    while len(new_obs)<NUM_OBS_PER_ITER:\n",
    "        obs = env.reset()\n",
    "        obs-=mean\n",
    "        obs/=stdev\n",
    "        reward=0\n",
    "        steps=0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action=sess.run(output,feed_dict={x:obs[None,:]})\n",
    "            #print action\n",
    "            obs,r,done,_=env.step(action)\n",
    "            obs-=mean\n",
    "            obs/=stdev\n",
    "            reward+=r\n",
    "            steps+=1\n",
    "            if steps % 100 == 0: \n",
    "                print(\"%i/%i\"%(steps, max_steps))\n",
    "            if RENDER:\n",
    "                env.render()\n",
    "            if steps>max_steps:\n",
    "                break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
